{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLDisQ6gAaMQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pwyZu2ibAhO1",
    "outputId": "01503b88-86a2-4619-d029-6ba8a7632cd8"
   },
   "outputs": [],
   "source": [
    "def loadIrisData():\n",
    "    iris = load_iris()\n",
    "    X=iris['data']\n",
    "    t=iris['target']\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48_5__HzBks_"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(t_indices, N):\n",
    "    '''\n",
    "    Inputs:\n",
    "        t_indices: list of indices\n",
    "        N: total no. of classes\n",
    "    '''\n",
    "    assert N>max(t_indices), (N, max(t_indices))\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    return t_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2DsnXa89lIk"
   },
   "outputs": [],
   "source": [
    "def test_one_hot_encoding():\n",
    "    t_1hot = one_hot_encoding([0,2], 3)\n",
    "    t_1hotTrue = np.array([[1.,0.,0.], [0.,0.,1.]])\n",
    "    assert np.all(np.isclose( t_1hot, t_1hotTrue ))\n",
    "    print('Test passed', '\\U0001F44D')\n",
    "if __name__==\"__main__\":\n",
    "    test_one_hot_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXxxA2YkB_I8"
   },
   "outputs": [],
   "source": [
    "def splitData(X,t,testFraction=0.2):\n",
    "    \"\"\"\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: np array of shape (Nsamples, dim)\n",
    "        t: np array of len Nsamples; can be one hot vectors or labels\n",
    "        testFraction: (float) Nsamples_test = testFraction * Nsamples\n",
    "    \"\"\"\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_splitData():\n",
    "    X = np.random.random((5,2))\n",
    "    t1hot = one_hot_encoding([1,0,2,1,2],3)\n",
    "    X_train, t1hot_train, X_test, t1hot_test = splitData(X,t1hot,.2)\n",
    "    assert X_train.shape==(4,2), [\"X_train.shape\", X_train.shape]\n",
    "    assert X_test.shape==(1,2), [\"X_test.shape\", X_test.shape]\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK2lZ6ZpCjAg"
   },
   "outputs": [],
   "source": [
    "### Normalize data to be of zero mean and unit variance\n",
    "def normalizeX(X_train, X_test):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X_train: np array 2d\n",
    "        X_test: np array 2d\n",
    "    Outputs:\n",
    "        Normalized np arrays 2d\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    return X_train_normalized, X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normalizeX():\n",
    "    X_train = np.array([[1,1,0],[2,2,1]])\n",
    "    X_test = np.array([[1,1,0],[3,3,2]])\n",
    "    X_train_normalized, X_test_normalized = normalizeX(X_train, X_test)\n",
    "    a = np.array([[-1.,-1.,-1.], [ 1., 1., 1.]])\n",
    "    b = np.array([[-1.,-1.,-1.], [ 3., 3., 3.]])\n",
    "    assert np.all(np.isclose( X_train_normalized, a )), a\n",
    "    assert np.all(np.isclose( X_test_normalized, b )), b\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_normalizeX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ_OSEoQLEuc"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sigmoid():\n",
    "    x = np.array([np.log(4),np.log(0.25),0])\n",
    "    y = sigmoid(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.8, 0.2, 0.5]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_softmax():\n",
    "    x = np.array([np.log(2),np.log(7),0])\n",
    "    y = softmax(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.2, 0.7, 0.1]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iwi4QwxlOAOR"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape; it is sigmoid layer's output\n",
    "    Output:\n",
    "        y: numpy array of same shape as x; it is the derivative of sigmoid\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        '''   \n",
    "        Input:\n",
    "            ni: int, size of input layer\n",
    "            nh: int, size of hidden layer\n",
    "            no: int, size of output layer\n",
    "        Action:\n",
    "            Creates instance variables\n",
    "        NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
    "        '''\n",
    "        self.ni = ni\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "        self.weights1 = []\n",
    "        self.weights2 = []\n",
    "        return\n",
    "    \n",
    "    def init_weights():\n",
    "        '''\n",
    "        Action:\n",
    "            Randomly initialize weights1 and weights2 with proper size random np arrays\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        return v2\n",
    "\n",
    "    def backprop(self,x,y,eta):\n",
    "        '''\n",
    "        # application of the chain rule to find derivative of the categorical cross entropy loss function with respect to weights2 and weights1\n",
    "        Input:\n",
    "            x: numpy array of shape (ni,1)\n",
    "            y: numpy array of shape (no,1)\n",
    "            eta: learning rate\n",
    "        Action:\n",
    "            # Finding the derivatives\n",
    "            del_weights2: np array that stores the derivative of the loss function with respect to weights2\n",
    "            del_weights1: np array that stores the derivative of the loss function with respect to weights1\n",
    "\n",
    "            # Update the weights with the derivative of the categorical cross entropy loss function\n",
    "              weights1 += eta*del_weights1\n",
    "              weights2 += eta*del_weights2\n",
    "        ''' \n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "\n",
    "    def fit(self, X, t, eta, epochs):\n",
    "        '''\n",
    "        input:\n",
    "            X: training input data \n",
    "            t: training targets\n",
    "            eta: learning rate\n",
    "            epochs: number of epochs\n",
    "        Action:\n",
    "            train the weights\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "        \n",
    "    def predict_label(self,x):    \n",
    "        '''\n",
    "        Output:\n",
    "            y: np array of index\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fmR8F2JIFwqm",
    "outputId": "fa868689-92c8-4a43-882f-3321cde1a301"
   },
   "outputs": [],
   "source": [
    "### Lastly, report the accuracy of your model and print the Confusion Matrix\n",
    "#printing the confusion matrix\n",
    "def getCM(y,t):\n",
    "    '''\n",
    "    Inputs:\n",
    "        y: estimated labels np array (Nsample,1)\n",
    "        t: targets np array (Nsamples,1)\n",
    "    Outputs:\n",
    "        CM : np array of confusion matrix\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "Use the above functions to carry out the experiment:\n",
    "- load iris data and prepare it for NN\n",
    "- split randomly into 20% test data\n",
    "- create a NN with 1 hidden layer\n",
    "- train the network with training data\n",
    "- Plot loss w.r.t. number of epochs\n",
    "- Print confusion matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hewsBv12weZ2",
    "outputId": "52407420-e7e5-4ca6-952b-6448ffe4b101"
   },
   "outputs": [],
   "source": [
    "def experiment():\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 10 MARKS\n",
    "\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BP_Iris.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
